\chapter{Introduction}


Software systems are getting more integrated with our day-to-day life and have more impact of the society, thus, there is a need for these systems to be designed in a way that are more aligned with norms of society (or policies, or regulations)\cite{Something}. This means norms and policies should be considered as part of system development and maintenance cycles by the designers and developers. On the other hand, systems affect the society and by extension they are also affecting the norms, so they should be already considered when policy-makers are analyzing existing norms or implementing new ones. Taking modelling and model execution as a principal approach to designing both systems and norms, intuitively, requires the designers to be able to model these concepts, which include executable models of norms, models of the system, and, the social setting and its actors. The expressivity and flexibility required to encompass these aspects is not trivial. It is no longer just the model of a system, a social setting, and set of norms, but, it is a system that is utilized by social actors and governed by norms, a social setting that utilize and monitor a software system and decide upon, modify, analyze and enforce the norms, and, norms that regulate the system and the social setting that have impacts on both. 


The purpose of this thesis is to closely study the interactions between these concepts, search for fundamental gaps in current methodologies utilized by system designers and policy makers, with the goal of finding approaches for creating more expressive and tangible models that are also flexible enough for specifying different scenarios and use-cases in different fields. To propose realistic methods, aside from the theoretical analysis, proof-of-concept tools have also been developed at each step and are presented.

\paragraph{Social Norms}
A central theme in this thesis are norms. The definition of norms for specific use-cases is specified in corresponding chapters, but, it is valuable to set the tone on the complexity of this concept. The daily social life of a human is filled with objectively complex interactions, but somehow we are able to navigate these dynamic and nondeterministic interactions with sufficiently low allocation of processing resources. A concept that vastly helps us in doing so is norms, by defining what a person should or should not do and what is expected to happen or not to happen in certain contexts and conditions, norms drive the actions in our fairly complex interactions. When we encounter a friend, among all the actions available to us we choose saying a word and among all the words in the dictionary we choose ``hi'' or "hello'' with the highest probability to say to them and if all the conditions are right, we expect to hear ``hi'' back in a few seconds, or, after we hand in the money to a shop owner the next action we expect them to perform is to hand in the item that we just paid for. The fascinating thing about norms is that in these situations all parties involved are internally aware of the process and they can act accordingly. We can even deduce the (most probable) correct process in face of highly dynamic and nondeterministic situations with a multitude of variables. It looks like somehow we have converged very closely to a set of highly abstract, parameterized, context-based, and flexible scenarios for interactions defined by norms, with predefined placeholders for different roles each with their own script, and most of the time we can precisely interpret a situation, choose the correct scenario and instantly fill the parameters and role placeholders with qualified values and deduce some sort of decision tree that tells us how an interaction can and should move forward.

These scenarios are context-based, imagine again encountering a friend, but in two different context: once in their neighborhood where you see them every day and once somewhere on the other side of the world; while the first scenario perfectly matches the saying ``hi'' context, the second one has a completely different context and will result in a substantially different concretization. Furthermore, we can even parameterize these interactions fairly easily, for example we can qualify actual people and put them in proper roles, in fact the role of the friend or the shop owner can be filled with anybody including ourselves.

The scenarios defined by norms are also highly dynamic and flexible. During an interaction we are constantly monitoring the scenario for deviations from what we expect to occur. Some deviations can be negligible: while somewhat unexpected, they do not change the context of the interaction completely, like not hearing ``hi'' back from the friend, maybe they did not hear. However, some deviations completely change the context, like just getting an angry look from your friend instead of hearing ``hi''. What is interesting about deviations is that we even have modular and predefined contingency plans for when a concrete scenario is not played according to expectations. These plans can vary from attempting to fix the concrete scenario, like saying ``hi'' louder after not getting a response, to revising the beliefs about a context like removing a particular person from the friend role to even rewriting the plans altogether like never saying ``hi'' to friends anymore.



\paragraph{Model of Agency}
Agency is another concept that is central to this work. Software systems are generally considered to be void of real agency and are controlled through specific control structures, even if those structures consist of probabilistic flows. This assumption get fuzzy when it comes to social actors, like humans, as without access to fully developed artificial general intelligence, it is hard to claim that a software agent has agency. Then the question is how do we model such agents? In my observation in creating executable models of social agents, the most important requirements are (1) how expressive is the decision-making of the agents and (2) how efficient is the execution of the agents. Depending on the use-case, one of these two becomes more important than the other. When the purpose of the research is to study the outcome of a social phenomena in certain settings without regards to the model of the input agent, efficient execution should be focused. An example of these approaches is the simulations of disaster response systems, where purpose of the study is to find the optimal settings or reactions to minimize damage. In these cases the agents are generally considered to have mathematical specifications that encompass a relatively realistic representation of how a person will respond to a natural disaster \cite{Something}.

In contrast, in some use-cases the expressivity of the input models of agents are more important, meaning even if the execution is less efficient, it is worth to have self-explanatory and readable models. These are the cases where the purpose of the study is to analyze the agents without much regard to optimizing an outcome. The study of norms and normative agents is an example where these approaches are far more adopted, as the transparency of the decision-making becomes more important in analyzing and explaining (non-)compliant behaviors. This research intrinsically falls into this category, and, as it will be presented in later chapters, the Belief-Desire-Intention (BDI) model of agency \cite{Something} is utilized in modelling agents. By specifying agents in terms of human-related attitudes, BDI agents are suitable in modelling social agents. More interestingly, a lot of the concepts defined in the previous section about norms, like norms creating decision-tree in our mind that can be matched and concretized in certain situations, or having contingency plans for failures are all already (partially) identified by BDI models. 


\section{Motivation and Research Questions}

\section{Approach and Scope of this Thesis}

\section{Policy-Making Scenarios}

\section{Research Collaborations}
Peter, Xin, Lu-Chi, Giovanni, Lu, Sarah, and, Thomas go here.