\chapter{Introduction}
Software systems are getting more integrated with our day-to-day life and have more impact of the society, thus, there is a need for these systems to be designed in a way that are more aligned with norms of society (or policies, or regulations)\cite{Something}. This means norms and policies should be considered as part of system development and maintenance cycles by the designers and developers. On the other hand, systems affect the society and by extension they are also affecting the norms, so they should be already considered when policy-makers are analyzing existing norms or implementing new ones. Taking modelling and model execution as a principal approach to designing both systems and norms, intuitively, requires the designers to be able to model these concepts, which include executable models of norms, models of the system, and, the social setting and its actors. The expressivity and flexibility required to encompass these aspects is not trivial. It is no longer just the model of a system, a social setting, and set of norms, but, it is a system that is utilized by social actors and governed by norms, a social setting that utilize and monitor a software system and decide upon, modify, analyze and enforce the norms, and, norms that regulate the system and the social setting that have impacts on both. 


The purpose of this thesis is to closely study the interactions between these concepts, search for fundamental gaps in current methodologies utilized by system designers and policy makers, with the goal of finding approaches for creating more expressive and tangible models that are also flexible enough for specifying different scenarios and use-cases in different domain to assist in both system design and policy-making. To propose realistic methods, aside from the theoretical analysis, proof-of-concept tools have also been developed or adopted at each step and are presented.


\paragraph{Social Norms}
A central theme in this thesis are norms. The definition of norms for specific use-cases is specified in corresponding chapters, but, it is valuable to set the tone on the complexity of this concept. The daily social life of a human is filled with objectively complex interactions, but somehow we are able to navigate these dynamic and nondeterministic interactions with sufficiently low allocation of processing resources. A concept that vastly helps us in doing so is norms, by defining what a person should or should not do and what is expected to happen or not to happen in certain contexts and conditions, norms drive the actions in our fairly complex interactions. When we encounter a friend, among all the actions available to us we choose saying a word and among all the words in the dictionary we choose ``hi'' or "hello'' with the highest probability to say to them and if all the conditions are right, we expect to hear ``hi'' back in a few seconds, or, after we hand in the money to a shop owner the next action we expect them to perform is to hand in the item that we just paid for. The fascinating thing about norms is that in these situations all parties involved are internally (somewhat) aware of the process and they can act accordingly. We can even deduce the (most probable) correct process in face of highly dynamic and nondeterministic situations with a multitude of variables. It looks like somehow we have converged very closely to a set of highly abstract, parameterized, context-based, and flexible scenario templates or partial plans for interactions defined by norms, with predefined placeholders for different roles each with their own script, and most of the time we can (almost) precisely interpret a situation, choose the correct template and instantly fill the parameters and role placeholders with qualified values and infer some sort of decision tree that tells us how an interaction can and should move forward.


These scenario templates are context-based, imagine again encountering a friend, but in two different context: once in their neighborhood where you see them every day and once somewhere on the other side of the world; while the first template perfectly matches the saying ``hi'' scenario context, the second one has a completely different context and will result in a substantially different concretization. Furthermore, we can even parameterize these interactions fairly easily, for example we can qualify actual people and put them in proper roles, in fact the role of the friend or the shop owner can be filled with anybody including ourselves.


The scenario templates defined by norms are also highly dynamic and flexible. During an interaction we are constantly monitoring the scenario for deviations from what we expect to occur. Some deviations can be negligible: while somewhat unexpected, they do not change the context of the interaction completely, like not hearing ``hi'' back from the friend, maybe they did not hear. However, some deviations completely change the context, like just getting an angry look from your friend instead of hearing ``hi''. What is interesting about deviations is that we even have modular and predefined contingency plans for when a concrete scenario is not played according to expectations of its template. These plans can vary from attempting to fix the concrete scenario, like saying ``hi'' louder after not getting a response, to revising the beliefs about a context like removing a particular person from the qualifications that makes them suitable for the friend role to even rewriting the plans altogether like never saying ``hi'' to friends anymore.


\paragraph{Models of Agency}
Agency is another concept that is central to this work. Software systems are generally considered to be void of real agency and are controlled through specific control structures, even if those structures consist of probabilistic flows that can change as the system interacts with its environment like in case of reinforcement learning they still have a controll structure. This assumption get fuzzy when it comes to computational models of social actors, like humans, as without access to fully developed artificial general intelligence, it is hard to claim that a software agent has agency. Then the question is how do we model such agents? There are two main approaches used in the field to model concepts of agency such as objectives and preferences, namely these approaches are (1) modelling agents in terms of variables and mathematical functions, and, (2) modelling agents in terms of agent-oriented programs often in the form of logic-based behaviorial specifications. The first approach has many advantages, firstly, mathematical models are often more efficient in execution resulting in such models being more scalable. Also, defining agents in terms of a few variables makes them easier for experimentations particularily in simulations, and, it also makes them much easier to manipulate at run-time, to simulate adaptation and learning processes. In general, when the purpose of a research is to study the outcome of a social phenomena in certain settings without regards to the model of the input agent, mathematical models are suitable. An example of these approaches is the simulations of disaster response systems, where purpose of the study is to find the optimal settings or reactions to minimize damage. In these cases the agents are generally considered to have mathematical specifications that encompass a relatively realistic representation of how a person will respond to a natural disaster by avoiding danger as their utility function\cite{Something}.


Where mathematical models fall short and logic-based programmable models are advantagous is studies where expressivity and transparency if the models is the principal point. In these cases, even if the execution is less efficient and adaptability is harder to achieve, it is still worth to have self-explanatory and readable models. These are the cases where the purpose of the study is to analyze the agents without much regard to optimizing an outcome and often there is no obvious utility to optimize in the setting anyways. The study of norms and normative agents is one domain where these approaches are far more adopted, as the transparency of the decision-making becomes more important in analyzing and explaining (non-)compliant behaviors. This research intrinsically falls into this category, and, as it will be presented in later chapters, the Belief-Desire-Intention (BDI) model of agency \cite{Something} is utilized in modelling agents. By specifying agents in terms of human-related attitudes, BDI agents are suitable in modelling social agents. More interestingly, a lot of the concepts defined in the previous section about norms, like norms creating decision-tree in our mind that can be matched and concretized in certain situations, or having contingency plans for failures are all already (partially) identified by BDI models.


\paragraph{System Compliance}
Software systems that affect members of a society, should be compliant to the norms of that society. There are multiple ways to ensure compliance in a system, depending on the size, complexity of the system, norms that govern it and the governance bodies that are concerned with monitoring and regulating it. Some policies can be operataionalized in terms of access control. For example some software systems with pre-defined and static internal policies can be developed with the policies already hard-coded in them, intuitively, this is most effiecient approach whilest being the least maintainable. There are systems that use run-time policy-making protocols like LDAP to make sure the software is running in a compliant manner by e.g., taking permission from policy enforcement points that take advise from policy decision points which in turn retrieve policies from policy information point. Then by modifying the policies in information points, the system administrators can control enforced policies without changing the software itself. These approaches are arguebly suitable for many systems, until the point that policies in question become more complicated than simple non-conflicting, non-contradicting, easy to intepret regulative norms defined in terms of deontic notions of permissions, obligations and prohibitions implemetented in the form of ex-ante access rules. As it is observed in the literature, and multiple examples presented in this thesis show that social norms do indeed become more complex much sooner than anticipated by many works and in fact are vastly simplified in current compliance-checking approaches. 


Firslty, norms are more than a set of formal rules extracted from a legislative text: they emerge from multiple sources with different degrees of priority, they require interpretation to be encoded and qualification to be applied within a social context. Furthermore, they continuously adapt, in both expression and application~\cite{Boella2014APractice}. Furthermore, in any given context there are multiple normative sources may be concurrently relevant, and/or multiple interpretations of the same normative sources may be available (e.g. retrieved from previous cases), and these may be possibly conflicting. This makes conflict resolution and interpretation detrimental parts of compliance-checking.


Furthermore, norms that are traditionally distinguished between \textit{regulative} and \textit{constitutive} norms~\cite{Searle1969,Boella2004RegulativeSystems,Sileno2015}. Regulative norms regulate behaviors that exist independent of the norms and are generally prescribed in terms of \textit{permissions}, \textit{obligations} and, \textit{prohibitions} (e.g. traffic regulations). Constitutive norms determine that some entity (e.g. an object, a situation, a certain agent, a certain behaviour) ``counts as'' something else, creating a new institutional entity that does not exist independently of these norms. (for example, the concept of marriage or money as a legal means of payment). The concept of institutional power is particularly relevant in the context of constitutive norms, as it is used to ascribe institutional meaning to  performances (e.g. raising a hand counts as a bid during an auction). A conceptual framework that instead contains both deontic and potestative dimensions is the one proposed by Hohfeld \cite{hohfeld1917fundamental}, whereas deontic logics, although much more popular, by definition focuses on regulative norms. This work tries to take a step in the direction of 


\section{Motivation and Research Questions}
The overarching motivation of this research started has been in creation of a digital data market-places (DMP) specially in the field of ligistics data. The need for data is exponentially increasing in all research and industries, and an environment like a DMP can provide different parties a place to share (or buy and sell) scientific or corporate data with each other. Although the presence of such environment can vastly improve the efficiency of data-oriented research and even prevent issues like data monopolies, there are certain risks involved, such as privacy issues, competetive corporate advantages, and, legal problems. As more countries (and other authorotive bodies) are implementing regulations to govern data transactions, such sharing environment needs to be compliant with these regulations, also actors in these markets like organizations and companies may have ad-hoc contractual agreements about data-sharing, and, they may also have internal policies like user agreements about how they can share data. The complexities of the market-places alongside the requirement for compliance results in a need for approaches to automate governance. This work started by focusing exactly that, how do we do make data-sharing compliant? However, during this research it turned out that it is not only data-sharing use-cases that are in need of such methods. More aspects of our day-to-day life are being \textit{controlled} by automated processes; visa applications, job applications, credit placements, mortgage and insurance are just a few examples and one can only imagine that the list will continue to grow as time goes on. Even if data-sharing regulations are a relatively new phenomena, when taken in a broader sense, there are already regulations implemented for these domains, and when then the decisions are made in an automated manner, then the question becomes how do we do we make any automated process compliant to arbitrary (regulative and consitutive) norms?





\section{Approach and Scope of this Thesis}

\section{Policy-Making Scenarios}

\section{Research Collaborations}
Peter, Xin, Lu-Chi, Giovanni, Lu, Sarah, and, Thomas go here.